# ğŸ§  CNN Training: Standard vs Memory-Efficient Approaches

This repository explores two distinct methods of training Convolutional Neural Networks (CNNs) for image classification:

- **Standard Approach**: Loading the dataset into memory.
- **Memory-Efficient Approach**: Streaming images directly from URLs to conserve RAM usage.

By comparing these workflows, this project provides insight into practical deep learning on machines with limited memory resources.

---

## ğŸ“ Project Structure

```bash
ğŸ“¦CNN-Training-Memory-Efficient
 â”£ ğŸ““ CNN_training.ipynb
 â”£ ğŸ““ CNN_training_memory_save.ipynb
 â”£ ğŸ““ Data_preprocessing.ipynb
 â”— ğŸ““ Data_preprocessing_memory_save.ipynb

 ---
```


## ğŸš€ Key Features

- âœ… CNN implementation using TensorFlow/Keras
- âœ… Efficient memory-saving techniques (image streaming)
- âœ… Dataset preprocessing with and without memory constraints
- âœ… Training and evaluation pipeline
- âœ… Clear performance comparison (speed, RAM usage, accuracy)

